{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Security Data Analysis Workshop\n",
    "## Blue Team Focus: When to use AI/ML vs Basic Methods\n",
    "\n",
    "This notebook demonstrates when to use simple statistical methods vs machine learning \n",
    "for cybersecurity analysis. Each module compares both approaches with realistic datasets.\n",
    "\n",
    "## Setup and Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---\n",
    "# Module 1: The Overwhelmed SOC Analyst\n",
    "# **Persona**: Junior analyst drowning in 50,000 daily log entries\n",
    "# \n",
    "# **Scenario**: You have network traffic logs and need to quickly identify suspicious activity.\n",
    "# \n",
    "# **Question**: Should you use Excel pivot tables or machine learning?\n",
    "\n",
    "# 1.1 Generate Network Traffic Dataset\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network_traffic_data(num_records=10000):\n",
    "    \"\"\"Generate realistic network traffic data with hidden anomalies\"\"\"\n",
    "    \n",
    "    # Normal traffic patterns\n",
    "    normal_sources = [f\"192.168.1.{i}\" for i in range(10, 100)]\n",
    "    normal_destinations = [f\"10.0.{i}.{j}\" for i in range(1, 5) for j in range(10, 50)]\n",
    "    common_ports = [80, 443, 22, 25, 53, 110, 143, 993, 995]\n",
    "    \n",
    "    # Generate timestamps over last 24 hours\n",
    "    start_time = datetime.now() - timedelta(hours=24)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Normal traffic (90% of data)\n",
    "    for _ in range(int(num_records * 0.90)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 86400))\n",
    "        source = random.choice(normal_sources)\n",
    "        destination = random.choice(normal_destinations)\n",
    "        port = random.choice(common_ports)\n",
    "        bytes_sent = random.randint(64, 1500)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'source_ip': source,\n",
    "            'destination_ip': destination,\n",
    "            'destination_port': port,\n",
    "            'bytes': bytes_sent,\n",
    "            'protocol': 'TCP'\n",
    "        })\n",
    "    \n",
    "    # Suspicious traffic (10% of data) - More obvious for Excel detection\n",
    "    suspicious_ips = ['185.220.70.43', '194.233.164.24', '91.234.99.12']\n",
    "    suspicious_ports = [1337, 4444, 8080, 9999, 31337]\n",
    "    \n",
    "    for _ in range(int(num_records * 0.10)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 86400))\n",
    "        \n",
    "        if random.random() < 0.4:  # External suspicious IP\n",
    "            source = random.choice(suspicious_ips)\n",
    "            destination = random.choice(normal_destinations)\n",
    "            port = random.choice(suspicious_ports)\n",
    "            bytes_sent = random.randint(5000, 50000)  # Much larger transfers\n",
    "        else:  # Internal lateral movement\n",
    "            source = random.choice(normal_sources)\n",
    "            destination = random.choice(normal_sources)\n",
    "            port = random.choice(suspicious_ports)\n",
    "            bytes_sent = random.randint(2000, 10000)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'source_ip': source,\n",
    "            'destination_ip': destination,\n",
    "            'destination_port': port,\n",
    "            'bytes': bytes_sent,\n",
    "            'protocol': 'TCP'\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df.sample(frac=1).reset_index(drop=True)  # Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Generated 500,000 network traffic records\n",
      "üìÖ Time range: 2025-07-16 09:10:55 to 2025-07-17 09:10:55\n",
      "üíæ Saved to network_traffic.csv\n",
      "\n",
      "üîç Sample of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source_ip</th>\n",
       "      <th>destination_ip</th>\n",
       "      <th>destination_port</th>\n",
       "      <th>bytes</th>\n",
       "      <th>protocol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-16 14:00:45</td>\n",
       "      <td>192.168.1.23</td>\n",
       "      <td>10.0.4.24</td>\n",
       "      <td>53</td>\n",
       "      <td>1481</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-16 22:08:13</td>\n",
       "      <td>192.168.1.27</td>\n",
       "      <td>10.0.1.21</td>\n",
       "      <td>53</td>\n",
       "      <td>1129</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-16 13:43:28</td>\n",
       "      <td>192.168.1.16</td>\n",
       "      <td>10.0.1.38</td>\n",
       "      <td>25</td>\n",
       "      <td>1268</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-17 07:31:23</td>\n",
       "      <td>192.168.1.82</td>\n",
       "      <td>10.0.2.23</td>\n",
       "      <td>25</td>\n",
       "      <td>1498</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-17 06:31:47</td>\n",
       "      <td>192.168.1.79</td>\n",
       "      <td>10.0.2.10</td>\n",
       "      <td>25</td>\n",
       "      <td>472</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp     source_ip destination_ip  destination_port  bytes  \\\n",
       "0 2025-07-16 14:00:45  192.168.1.23      10.0.4.24                53   1481   \n",
       "1 2025-07-16 22:08:13  192.168.1.27      10.0.1.21                53   1129   \n",
       "2 2025-07-16 13:43:28  192.168.1.16      10.0.1.38                25   1268   \n",
       "3 2025-07-17 07:31:23  192.168.1.82      10.0.2.23                25   1498   \n",
       "4 2025-07-17 06:31:47  192.168.1.79      10.0.2.10                25    472   \n",
       "\n",
       "  protocol  \n",
       "0      TCP  \n",
       "1      TCP  \n",
       "2      TCP  \n",
       "3      TCP  \n",
       "4      TCP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the dataset\n",
    "traffic_df = generate_network_traffic_data(500000)\n",
    "print(f\"üìä Generated {len(traffic_df):,} network traffic records\")\n",
    "print(f\"üìÖ Time range: {traffic_df['timestamp'].min()} to {traffic_df['timestamp'].max()}\")\n",
    "\n",
    "# Save to CSV for Excel analysis\n",
    "traffic_df.to_csv('network_traffic.csv', index=False)\n",
    "print(\"üíæ Saved to network_traffic.csv\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(traffic_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Basic Analysis (Excel-Style in Python)\n",
    "**Let's generate some basic statistics! You can use a tool like Excel for this**\n",
    "**type of analysis, but you can also do this using python and pandas!**\n",
    "\n",
    "Let's look for:\n",
    "- Top talkers by bytes sent\n",
    "- Unusual ports (simple frequency analysis)\n",
    "- Large transfers (95th percentile threshold)\n",
    "- Quick suspicious IP identification based on a pre-determined list of \"suspicious\" IPs\n",
    "\n",
    "Pros:\n",
    "- Very quick analysis\n",
    "- Summary statistics\n",
    "- Explainable!\n",
    "\n",
    "Cons:\n",
    "- No insight into complex behavior patterns\n",
    "- Must pre-determine statistics you want to examine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_traffic_analysis(df):\n",
    "    \"\"\"Basic analysis that mirrors Excel pivot tables and filters\"\"\"\n",
    "    \n",
    "    print(\"üîé BASIC ANALYSIS (Excel-style approach)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Analysis 1: Top talkers by bytes sent\n",
    "    print(\"\\nüìà TOP 10 SOURCES BY TOTAL BYTES:\")\n",
    "    top_sources = df.groupby('source_ip')['bytes'].agg(['sum', 'count', 'mean']).round(2)\n",
    "    top_sources.columns = ['total_bytes', 'connections', 'avg_bytes']\n",
    "    top_sources = top_sources.sort_values('total_bytes', ascending=False)\n",
    "    print(top_sources.head(10))\n",
    "    \n",
    "    # Analysis 2: Unusual ports (simple frequency analysis)\n",
    "    print(\"\\nüîç UNUSUAL PORTS (used ‚â§ 5 times):\")\n",
    "    port_counts = df['destination_port'].value_counts()\n",
    "    unusual_ports = port_counts[port_counts <= 5]\n",
    "    print(f\"Found {len(unusual_ports)} unusual ports:\")\n",
    "    print(unusual_ports.head(10))\n",
    "    \n",
    "    # Analysis 3: Large transfers (95th percentile threshold)\n",
    "    threshold = df['bytes'].quantile(0.95)\n",
    "    large_transfers = df[df['bytes'] > threshold]\n",
    "    print(f\"\\nüìä LARGE TRANSFERS (> {threshold:,.0f} bytes):\")\n",
    "    print(f\"Found {len(large_transfers)} large transfers\")\n",
    "    \n",
    "    large_by_source = large_transfers.groupby('source_ip').agg({\n",
    "        'bytes': ['count', 'sum', 'max'],\n",
    "        'destination_port': lambda x: list(x.unique())\n",
    "    })\n",
    "    large_by_source.columns = ['transfer_count', 'total_bytes', 'max_bytes', 'ports_used']\n",
    "    print(large_by_source.head())\n",
    "    \n",
    "    # Quick suspicious IP identification\n",
    "    suspicious_keywords = ['185.', '194.', '91.', '203.']\n",
    "    external_ips = df[df['source_ip'].str.contains('|'.join(suspicious_keywords), na=False)]\n",
    "    \n",
    "    print(f\"\\nüö® EXTERNAL SOURCE IPs:\")\n",
    "    if len(external_ips) > 0:\n",
    "        ext_summary = external_ips.groupby('source_ip').agg({\n",
    "            'bytes': ['count', 'sum'],\n",
    "            'destination_port': lambda x: list(x.unique())\n",
    "        })\n",
    "        ext_summary.columns = ['connections', 'total_bytes', 'ports_used']\n",
    "        print(ext_summary)\n",
    "    else:\n",
    "        print(\"No external IPs detected with basic pattern matching\")\n",
    "    \n",
    "    return {\n",
    "        'top_sources': top_sources,\n",
    "        'unusual_ports': unusual_ports,\n",
    "        'large_transfers': large_transfers,\n",
    "        'external_ips': external_ips\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé BASIC ANALYSIS (Excel-style approach)\n",
      "==================================================\n",
      "\n",
      "üìà TOP 10 SOURCES BY TOTAL BYTES:\n",
      "                total_bytes  connections  avg_bytes\n",
      "source_ip                                          \n",
      "185.220.70.43     184993788         6677   27706.12\n",
      "194.233.164.24    183768616         6696   27444.54\n",
      "91.234.99.12      181807859         6669   27261.64\n",
      "192.168.1.68        6348101         5496    1155.04\n",
      "192.168.1.67        6156459         5380    1144.32\n",
      "192.168.1.37        6151591         5438    1131.22\n",
      "192.168.1.13        6148111         5345    1150.25\n",
      "192.168.1.77        6137689         5474    1121.24\n",
      "192.168.1.85        6113239         5401    1131.87\n",
      "192.168.1.11        6110646         5416    1128.26\n",
      "\n",
      "üîç UNUSUAL PORTS (used ‚â§ 5 times):\n",
      "Found 0 unusual ports:\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "üìä LARGE TRANSFERS (> 8,310 bytes):\n",
      "Found 24997 large transfers\n",
      "               transfer_count  total_bytes  max_bytes  \\\n",
      "source_ip                                               \n",
      "185.220.70.43            6233    182060480      49991   \n",
      "192.168.1.10               64       587523       9989   \n",
      "192.168.1.11               80       733624       9987   \n",
      "192.168.1.12               69       631610       9979   \n",
      "192.168.1.13               90       814662       9947   \n",
      "\n",
      "                                    ports_used  \n",
      "source_ip                                       \n",
      "185.220.70.43  [9999, 8080, 4444, 31337, 1337]  \n",
      "192.168.1.10   [31337, 4444, 1337, 8080, 9999]  \n",
      "192.168.1.11   [4444, 8080, 1337, 31337, 9999]  \n",
      "192.168.1.12   [31337, 9999, 4444, 8080, 1337]  \n",
      "192.168.1.13   [9999, 4444, 8080, 1337, 31337]  \n",
      "\n",
      "üö® EXTERNAL SOURCE IPs:\n",
      "                connections  total_bytes                       ports_used\n",
      "source_ip                                                                \n",
      "185.220.70.43          6677    184993788  [9999, 8080, 4444, 31337, 1337]\n",
      "194.233.164.24         6696    183768616  [31337, 1337, 4444, 9999, 8080]\n",
      "91.234.99.12           6669    181807859  [1337, 31337, 4444, 9999, 8080]\n",
      "\n",
      "‚è±Ô∏è Basic analysis completed in 0.38 seconds\n"
     ]
    }
   ],
   "source": [
    "# Time the analysis\n",
    "start_time = time.time()\n",
    "basic_results = basic_traffic_analysis(traffic_df)\n",
    "basic_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Basic analysis completed in {basic_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Machine Learning Analysis\n",
    "**We will use an isolation forest to identify anomalies in this dataset.**\n",
    "\n",
    "**What is an isolation forest, and why would we use this type of algorithm?**\n",
    "The isolation forest algorithm is one ML algorithm which answers the question,\n",
    "\"Can you show me data points that are anomalous?\" This algorithm is one example \n",
    "of a machine learning algorithm that is relatively efficient and low memory, \n",
    "which makes it a great algorithm for large datasets. \n",
    "\n",
    "Pros:\n",
    "- Allows you to discover and examine complex behavior patterns\n",
    "- Incorporates context into your analysis\n",
    "- Depending on the features extracted, can be explainable.\n",
    "\n",
    "Cons:\n",
    "- The performance of the Isolation Forest algorithm is highly dependent on the selection of its parameters.  \n",
    "- More complex algorithm-- caution should be used if you don't know how it works!\n",
    "- Depending on the features, can be hard to explain!\n",
    "- May produce false positives/false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_traffic_analysis(df):\n",
    "    \"\"\"ML-based anomaly detection for network traffic\"\"\"\n",
    "    \n",
    "    print(\"ü§ñ MACHINE LEARNING ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Feature engineering: Create behavioral profiles per source IP\n",
    "    print(\"\\nüîß Creating behavioral features...\")\n",
    "    \n",
    "    features = df.groupby('source_ip').agg({\n",
    "        'bytes': ['sum', 'mean', 'std', 'max', 'count'],\n",
    "        'destination_ip': 'nunique',\n",
    "        'destination_port': ['nunique', lambda x: list(x)],\n",
    "        'timestamp': lambda x: (x.max() - x.min()).total_seconds() / 3600  # session duration in hours\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    features.columns = ['bytes_sum', 'bytes_mean', 'bytes_std', 'bytes_max', 'connection_count', \n",
    "                       'unique_destinations', 'unique_ports', 'ports_list', 'session_duration_hours']\n",
    "    \n",
    "    # Fill NaN values\n",
    "    features['bytes_std'] = features['bytes_std'].fillna(0)\n",
    "    \n",
    "    # Add derived features\n",
    "    features['avg_bytes_per_connection'] = features['bytes_sum'] / features['connection_count']\n",
    "    features['port_diversity'] = features['unique_ports'] / features['connection_count']\n",
    "    \n",
    "    # Check for suspicious ports based on pre-determined list of ports\n",
    "    suspicious_ports = [1337, 4444, 8080, 9999, 31337, 6666]\n",
    "    features['has_suspicious_ports'] = features['ports_list'].apply(\n",
    "        lambda ports: any(port in suspicious_ports for port in ports)\n",
    "    ).astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Created features for {len(features)} unique source IPs\")\n",
    "    print(\"\\nüìä Feature summary:\")\n",
    "    display(features[['bytes_sum', 'connection_count', 'unique_destinations', 'unique_ports', 'has_suspicious_ports']].describe())\n",
    "    \n",
    "    # Prepare features for ML (exclude non-numeric columns)\n",
    "    ml_features = features.drop(['ports_list'], axis=1)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(ml_features)\n",
    "    \n",
    "    # Apply Isolation Forest for anomaly detection\n",
    "    print(\"\\nüîç Applying Isolation Forest anomaly detection...\")\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42, n_estimators=100)\n",
    "    anomaly_labels = iso_forest.fit_predict(features_scaled)\n",
    "    \n",
    "    # Get anomaly scores\n",
    "    anomaly_scores = iso_forest.decision_function(features_scaled)\n",
    "    \n",
    "    # Add results back to features\n",
    "    features['anomaly_label'] = anomaly_labels\n",
    "    features['anomaly_score'] = anomaly_scores\n",
    "    \n",
    "    # Analyze anomalies\n",
    "    anomalies = features[features['anomaly_label'] == -1].sort_values('anomaly_score')\n",
    "    \n",
    "    print(f\"\\nüö® ANOMALOUS SOURCE IPs DETECTED: {len(anomalies)}\")\n",
    "    print(\"\\nTop 5 most anomalous IPs:\")\n",
    "    \n",
    "    for i, (ip, row) in enumerate(anomalies.head().iterrows()):\n",
    "        print(f\"\\n{i+1}. {ip} (anomaly score: {row['anomaly_score']:.3f})\")\n",
    "        print(f\"   üìä Total bytes: {row['bytes_sum']:,}\")\n",
    "        print(f\"   üîó Connections: {row['connection_count']}\")\n",
    "        print(f\"   üéØ Unique destinations: {row['unique_destinations']}\")\n",
    "        print(f\"   üîå Unique ports: {row['unique_ports']}\")\n",
    "        print(f\"   ‚ö†Ô∏è  Has suspicious ports: {'Yes' if row['has_suspicious_ports'] else 'No'}\")\n",
    "        print(f\"   üïê Session duration: {row['session_duration_hours']:.1f} hours\")\n",
    "        \n",
    "        # Show actual ports used\n",
    "        actual_data = df[df['source_ip'] == ip]\n",
    "        ports_used = actual_data['destination_port'].value_counts().head(5)\n",
    "        print(f\"   üîå Top ports: {dict(ports_used)}\")\n",
    "    \n",
    "    return {\n",
    "        'features': features,\n",
    "        'anomalies': anomalies,\n",
    "        'model': iso_forest,\n",
    "        'scaler': scaler\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ MACHINE LEARNING ANALYSIS\n",
      "==================================================\n",
      "\n",
      "üîß Creating behavioral features...\n",
      "‚úÖ Created features for 93 unique source IPs\n",
      "\n",
      "üìä Feature summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bytes_sum</th>\n",
       "      <th>connection_count</th>\n",
       "      <th>unique_destinations</th>\n",
       "      <th>unique_ports</th>\n",
       "      <th>has_suspicious_ports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.163845e+07</td>\n",
       "      <td>5376.344086</td>\n",
       "      <td>244.978495</td>\n",
       "      <td>13.709677</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.155305e+07</td>\n",
       "      <td>249.659616</td>\n",
       "      <td>15.659404</td>\n",
       "      <td>1.598781</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.589818e+06</td>\n",
       "      <td>5118.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.819111e+06</td>\n",
       "      <td>5290.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.910347e+06</td>\n",
       "      <td>5337.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.026578e+06</td>\n",
       "      <td>5389.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.849938e+08</td>\n",
       "      <td>6696.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bytes_sum  connection_count  unique_destinations  unique_ports  \\\n",
       "count  9.300000e+01         93.000000            93.000000     93.000000   \n",
       "mean   1.163845e+07       5376.344086           244.978495     13.709677   \n",
       "std    3.155305e+07        249.659616            15.659404      1.598781   \n",
       "min    5.589818e+06       5118.000000           160.000000      5.000000   \n",
       "25%    5.819111e+06       5290.000000           247.000000     14.000000   \n",
       "50%    5.910347e+06       5337.000000           248.000000     14.000000   \n",
       "75%    6.026578e+06       5389.000000           249.000000     14.000000   \n",
       "max    1.849938e+08       6696.000000           250.000000     14.000000   \n",
       "\n",
       "       has_suspicious_ports  \n",
       "count                  93.0  \n",
       "mean                    1.0  \n",
       "std                     0.0  \n",
       "min                     1.0  \n",
       "25%                     1.0  \n",
       "50%                     1.0  \n",
       "75%                     1.0  \n",
       "max                     1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Applying Isolation Forest anomaly detection...\n",
      "\n",
      "üö® ANOMALOUS SOURCE IPs DETECTED: 10\n",
      "\n",
      "Top 5 most anomalous IPs:\n",
      "\n",
      "1. 194.233.164.24 (anomaly score: -0.282)\n",
      "   üìä Total bytes: 183,768,616\n",
      "   üîó Connections: 6696\n",
      "   üéØ Unique destinations: 160\n",
      "   üîå Unique ports: 5\n",
      "   ‚ö†Ô∏è  Has suspicious ports: Yes\n",
      "   üïê Session duration: 24.0 hours\n",
      "   üîå Top ports: {8080: np.int64(1380), 4444: np.int64(1374), 31337: np.int64(1339), 9999: np.int64(1310), 1337: np.int64(1293)}\n",
      "\n",
      "2. 91.234.99.12 (anomaly score: -0.266)\n",
      "   üìä Total bytes: 181,807,859\n",
      "   üîó Connections: 6669\n",
      "   üéØ Unique destinations: 160\n",
      "   üîå Unique ports: 5\n",
      "   ‚ö†Ô∏è  Has suspicious ports: Yes\n",
      "   üïê Session duration: 24.0 hours\n",
      "   üîå Top ports: {1337: np.int64(1397), 8080: np.int64(1361), 31337: np.int64(1341), 9999: np.int64(1287), 4444: np.int64(1283)}\n",
      "\n",
      "3. 185.220.70.43 (anomaly score: -0.262)\n",
      "   üìä Total bytes: 184,993,788\n",
      "   üîó Connections: 6677\n",
      "   üéØ Unique destinations: 160\n",
      "   üîå Unique ports: 5\n",
      "   ‚ö†Ô∏è  Has suspicious ports: Yes\n",
      "   üïê Session duration: 24.0 hours\n",
      "   üîå Top ports: {8080: np.int64(1368), 4444: np.int64(1357), 31337: np.int64(1331), 1337: np.int64(1324), 9999: np.int64(1297)}\n",
      "\n",
      "4. 192.168.1.68 (anomaly score: -0.106)\n",
      "   üìä Total bytes: 6,348,101\n",
      "   üîó Connections: 5496\n",
      "   üéØ Unique destinations: 250\n",
      "   üîå Unique ports: 14\n",
      "   ‚ö†Ô∏è  Has suspicious ports: Yes\n",
      "   üïê Session duration: 24.0 hours\n",
      "   üîå Top ports: {110: np.int64(605), 53: np.int64(586), 22: np.int64(577), 80: np.int64(571), 143: np.int64(564)}\n",
      "\n",
      "5. 192.168.1.87 (anomaly score: -0.040)\n",
      "   üìä Total bytes: 5,656,137\n",
      "   üîó Connections: 5118\n",
      "   üéØ Unique destinations: 249\n",
      "   üîå Unique ports: 14\n",
      "   ‚ö†Ô∏è  Has suspicious ports: Yes\n",
      "   üïê Session duration: 24.0 hours\n",
      "   üîå Top ports: {993: np.int64(567), 995: np.int64(565), 443: np.int64(557), 25: np.int64(556), 143: np.int64(528)}\n",
      "\n",
      "‚è±Ô∏è ML analysis completed in 0.66 seconds\n"
     ]
    }
   ],
   "source": [
    "# Time the ML analysis\n",
    "start_time = time.time()\n",
    "ml_results = ml_traffic_analysis(traffic_df)\n",
    "ml_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è ML analysis completed in {ml_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä METHOD COMPARISON - MODULE 1\n",
      "==================================================\n",
      "üéØ ACTUAL SUSPICIOUS IPs: ['185.220.70.43', '194.233.164.24', '91.234.99.12']\n",
      "üîç BASIC METHOD found: ['185.220.70.43', '194.233.164.24', '91.234.99.12']\n",
      "ü§ñ ML METHOD found: ['194.233.164.24', '91.234.99.12', '185.220.70.43', '192.168.1.68', '192.168.1.87']...\n",
      "\n",
      "üìà DETECTION RESULTS:\n",
      "   Basic method detected: 3/3 suspicious IPs\n",
      "   ML method detected: 3/3 suspicious IPs\n",
      "\n",
      "‚è±Ô∏è TIMING COMPARISON:\n",
      "   Basic method: 0.38 seconds\n",
      "   ML method: 0.66 seconds\n",
      "   Speed difference: 1.7x slower\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "‚úÖ Use BASIC METHOD when:\n",
      "   ‚Ä¢ You need results very quickly\n",
      "   ‚Ä¢ Looking for known bad indicators\n",
      "   ‚Ä¢ Working with smaller dataset\n",
      "   ‚Ä¢ Need explainable results for management\n",
      "\n",
      "‚úÖ Use ML METHOD when:\n",
      "   ‚Ä¢ Unknown threat patterns\n",
      "   ‚Ä¢ Large datasets\n",
      "   ‚Ä¢ Building automated detection\n",
      "   ‚Ä¢ Complex behavioral analysis needed\n"
     ]
    }
   ],
   "source": [
    "def compare_methods_module1():\n",
    "    \"\"\"Compare the effectiveness of basic vs ML methods\"\"\"\n",
    "    \n",
    "    print(\"üìä METHOD COMPARISON - MODULE 1\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get the actual suspicious IPs from our data generation\n",
    "    actual_suspicious = ['185.220.70.43', '194.233.164.24', '91.234.99.12']\n",
    "    \n",
    "    # Basic method results\n",
    "    basic_suspicious = basic_results['external_ips']['source_ip'].unique() if len(basic_results['external_ips']) > 0 else []\n",
    "    \n",
    "    # ML method results\n",
    "    ml_suspicious = ml_results['anomalies'].index.tolist()\n",
    "    \n",
    "    print(f\"üéØ ACTUAL SUSPICIOUS IPs: {actual_suspicious}\")\n",
    "    print(f\"üîç BASIC METHOD found: {list(basic_suspicious)}\")\n",
    "    print(f\"ü§ñ ML METHOD found: {ml_suspicious[:5]}...\")  # Show top 5\n",
    "    \n",
    "    # Calculate detection rates\n",
    "    basic_detected = len(set(basic_suspicious) & set(actual_suspicious))\n",
    "    ml_detected = len(set(ml_suspicious) & set(actual_suspicious))\n",
    "    \n",
    "    print(f\"\\nüìà DETECTION RESULTS:\")\n",
    "    print(f\"   Basic method detected: {basic_detected}/{len(actual_suspicious)} suspicious IPs\")\n",
    "    print(f\"   ML method detected: {ml_detected}/{len(actual_suspicious)} suspicious IPs\")\n",
    "    \n",
    "    # Show timing comparison\n",
    "    print(f\"\\n‚è±Ô∏è TIMING COMPARISON:\")\n",
    "    print(f\"   Basic method: {basic_time:.2f} seconds\")\n",
    "    print(f\"   ML method: {ml_time:.2f} seconds\")\n",
    "    print(f\"   Speed difference: {ml_time/basic_time:.1f}x slower\")\n",
    "    \n",
    "    # When to use each method\n",
    "    print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "    print(\"‚úÖ Use BASIC METHOD when:\")\n",
    "    print(\"   ‚Ä¢ You need results very quickly\")\n",
    "    print(\"   ‚Ä¢ Looking for known bad indicators\")\n",
    "    print(\"   ‚Ä¢ Working with smaller dataset\")\n",
    "    print(\"   ‚Ä¢ Need explainable results for management\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Use ML METHOD when:\")\n",
    "    print(\"   ‚Ä¢ Unknown threat patterns\")\n",
    "    print(\"   ‚Ä¢ Large datasets\")\n",
    "    print(\"   ‚Ä¢ Building automated detection\")\n",
    "    print(\"   ‚Ä¢ Complex behavioral analysis needed\")\n",
    "\n",
    "compare_methods_module1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---\n",
    "# Module 2: The Incident Responder Under Pressure\n",
    "# **Persona**: IR team member with 30 minutes to determine if an alert is real\n",
    "# \n",
    "# **Scenario**: Authentication logs showing potential brute force attacks\n",
    "# \n",
    "# **Question**: Pivot tables or behavioral modeling?\n",
    "\n",
    "# 2.1 Generate Authentication Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_auth_logs(num_records=10000):\n",
    "    \"\"\"Generate authentication logs with brute force attacks\"\"\"\n",
    "    \n",
    "    # Normal users\n",
    "    normal_users = [f\"user{i:03d}\" for i in range(1, 201)]\n",
    "    normal_sources = [f\"192.168.{i}.{j}\" for i in range(1, 5) for j in range(10, 50)]\n",
    "    \n",
    "    # Attackers\n",
    "    attack_sources = ['203.0.113.15', '198.51.100.42', '192.0.2.123']\n",
    "    attack_targets = ['admin', 'administrator', 'root', 'service', 'guest']\n",
    "    \n",
    "    data = []\n",
    "    start_time = datetime.now() - timedelta(hours=6)\n",
    "    \n",
    "    # Normal successful logins (80%)\n",
    "    for _ in range(int(num_records * 0.8)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 21600))\n",
    "        user = random.choice(normal_users)\n",
    "        source = random.choice(normal_sources)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'username': user,\n",
    "            'source_ip': source,\n",
    "            'event_type': 'login_success',\n",
    "            'service': 'ssh'\n",
    "        })\n",
    "    \n",
    "    # Normal failed logins (15%)\n",
    "    for _ in range(int(num_records * 0.15)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 21600))\n",
    "        user = random.choice(normal_users)\n",
    "        source = random.choice(normal_sources)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'username': user,\n",
    "            'source_ip': source,\n",
    "            'event_type': 'login_failure',\n",
    "            'service': 'ssh'\n",
    "        })\n",
    "    \n",
    "    # Brute force attacks (5%)\n",
    "    for attacker_ip in attack_sources:\n",
    "        attack_start = start_time + timedelta(hours=random.randint(1, 4))\n",
    "        \n",
    "        # Generate rapid-fire attempts\n",
    "        for i in range(random.randint(50, 200)):\n",
    "            timestamp = attack_start + timedelta(seconds=i * random.randint(1, 5))\n",
    "            user = random.choice(attack_targets + normal_users[:20])\n",
    "            \n",
    "            data.append({\n",
    "                'timestamp': timestamp,\n",
    "                'username': user,\n",
    "                'source_ip': attacker_ip,\n",
    "                'event_type': 'login_failure',\n",
    "                'service': 'ssh'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def basic_auth_analysis(df):\n",
    "    \"\"\"Basic authentication analysis\"\"\"\n",
    "    \n",
    "    print(\"=== BASIC AUTH ANALYSIS ===\")\n",
    "    \n",
    "    # Failed login attempts by IP\n",
    "    failed_logins = df[df['event_type'] == 'login_failure']\n",
    "    ip_failures = failed_logins.groupby('source_ip').size().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\nTop IPs by failed login attempts:\")\n",
    "    print(ip_failures.head(10))\n",
    "    \n",
    "    # Brute force detection (simple threshold)\n",
    "    brute_force_threshold = 20\n",
    "    potential_attackers = ip_failures[ip_failures >= brute_force_threshold]\n",
    "    \n",
    "    print(f\"\\nPotential brute force attackers (>={brute_force_threshold} failures):\")\n",
    "    for ip, count in potential_attackers.items():\n",
    "        ip_data = failed_logins[failed_logins['source_ip'] == ip]\n",
    "        unique_users = ip_data['username'].nunique()\n",
    "        time_span = (ip_data['timestamp'].max() - ip_data['timestamp'].min()).total_seconds() / 60\n",
    "        print(f\"  {ip}: {count} failures, {unique_users} users, {time_span:.1f} minutes\")\n",
    "    \n",
    "    return potential_attackers\n",
    "\n",
    "def ml_auth_analysis(df):\n",
    "    \"\"\"ML-based authentication analysis\"\"\"\n",
    "    \n",
    "    print(\"\\n=== ML AUTH ANALYSIS ===\")\n",
    "    \n",
    "    # Create time-based features\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['minute'] = df['timestamp'].dt.minute\n",
    "    \n",
    "    # Aggregate by IP and time window (5-minute windows)\n",
    "    df['time_window'] = df['timestamp'].dt.floor('5min')\n",
    "    \n",
    "    features = df.groupby(['source_ip', 'time_window']).agg({\n",
    "        'username': 'nunique',\n",
    "        'event_type': lambda x: (x == 'login_failure').sum(),\n",
    "        'timestamp': 'count'\n",
    "    }).rename(columns={\n",
    "        'username': 'unique_users',\n",
    "        'event_type': 'failures',\n",
    "        'timestamp': 'total_attempts'\n",
    "    })\n",
    "    \n",
    "    # Calculate failure rate\n",
    "    features['failure_rate'] = features['failures'] / features['total_attempts']\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    # Apply clustering to find unusual patterns\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Use DBSCAN to find clusters\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "    clusters = dbscan.fit_predict(features_scaled)\n",
    "    \n",
    "    # Analyze outliers (cluster -1)\n",
    "    outliers = features[clusters == -1]\n",
    "    \n",
    "    print(f\"\\nOutlier authentication patterns detected: {len(outliers)}\")\n",
    "    \n",
    "    # Group outliers by IP\n",
    "    for ip in outliers.index.get_level_values('source_ip').unique()[:5]:\n",
    "        ip_outliers = outliers[outliers.index.get_level_values('source_ip') == ip]\n",
    "        print(f\"\\n{ip}:\")\n",
    "        print(f\"  Outlier time windows: {len(ip_outliers)}\")\n",
    "        print(f\"  Max failures in 5min: {ip_outliers['failures'].max()}\")\n",
    "        print(f\"  Max unique users in 5min: {ip_outliers['unique_users'].max()}\")\n",
    "        print(f\"  Max failure rate: {ip_outliers['failure_rate'].max():.2f}\")\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_auth_logs(num_records=8000):\n",
    "    \"\"\"Generate authentication logs with brute force attacks\"\"\"\n",
    "    \n",
    "    # Normal users and systems\n",
    "    normal_users = [f\"user{i:03d}\" for i in range(1, 150)]\n",
    "    service_accounts = ['backup_svc', 'monitoring_svc', 'db_service', 'web_service']\n",
    "    normal_sources = [f\"192.168.{i}.{j}\" for i in range(1, 5) for j in range(10, 50)]\n",
    "    \n",
    "    # Attack sources and targets\n",
    "    attack_sources = ['203.0.113.15', '198.51.100.42', '192.0.2.123', '185.199.108.153']\n",
    "    common_targets = ['admin', 'administrator', 'root', 'guest', 'test', 'user']\n",
    "    \n",
    "    data = []\n",
    "    start_time = datetime.now() - timedelta(hours=8)\n",
    "    \n",
    "    # Normal successful logins (70%)\n",
    "    for _ in range(int(num_records * 0.70)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 28800))\n",
    "        user = random.choice(normal_users + service_accounts)\n",
    "        source = random.choice(normal_sources)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'username': user,\n",
    "            'source_ip': source,\n",
    "            'event_type': 'login_success',\n",
    "            'service': random.choice(['ssh', 'rdp', 'web'])\n",
    "        })\n",
    "    \n",
    "    # Normal failed logins (20% - typos, expired passwords, etc.)\n",
    "    for _ in range(int(num_records * 0.20)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 28800))\n",
    "        user = random.choice(normal_users)\n",
    "        source = random.choice(normal_sources)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'username': user,\n",
    "            'source_ip': source,\n",
    "            'event_type': 'login_failure',\n",
    "            'service': random.choice(['ssh', 'rdp', 'web'])\n",
    "        })\n",
    "    \n",
    "    # Brute force attacks (10%)\n",
    "    for attacker_ip in attack_sources:\n",
    "        # Each attacker targets multiple accounts\n",
    "        attack_start = start_time + timedelta(hours=random.randint(1, 6))\n",
    "        \n",
    "        # Generate rapid-fire attempts\n",
    "        for i in range(random.randint(30, 120)):\n",
    "            timestamp = attack_start + timedelta(seconds=i * random.randint(1, 10))\n",
    "            \n",
    "            # Mix of common targets and real usernames\n",
    "            if random.random() < 0.6:\n",
    "                user = random.choice(common_targets)\n",
    "            else:\n",
    "                user = random.choice(normal_users[:30])  # Target real users too\n",
    "            \n",
    "            data.append({\n",
    "                'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'username': user,\n",
    "                'source_ip': attacker_ip,\n",
    "                'event_type': 'login_failure',\n",
    "                'service': 'ssh'\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df.sort_values('timestamp').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_df = generate_auth_logs(4000)\n",
    "print(f\"üìä Generated {len(auth_df):,} authentication records\")\n",
    "print(f\"üìÖ Time range: {auth_df['timestamp'].min()} to {auth_df['timestamp'].max()}\")\n",
    "\n",
    "# Save to CSV\n",
    "auth_df.to_csv('auth_logs.csv', index=False)\n",
    "print(\"üíæ Saved to auth_logs.csv\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(auth_df.head())\n",
    "\n",
    "# Quick overview\n",
    "print(f\"\\nüìà Event breakdown:\")\n",
    "print(auth_df['event_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2.2 Basic Analysis (Excel-Style)\n",
    "# **‚è±Ô∏è Time Limit: 5 minutes**\n",
    "\n",
    "# %%\n",
    "def basic_auth_analysis(df):\n",
    "    \"\"\"Basic authentication analysis using simple aggregations\"\"\"\n",
    "    \n",
    "    print(\"üîé BASIC AUTH ANALYSIS (Excel-style)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Analysis 1: Failed login attempts by source IP\n",
    "    failed_logins = df[df['event_type'] == 'login_failure']\n",
    "    \n",
    "    print(f\"\\nüìä FAILED LOGIN SUMMARY:\")\n",
    "    print(f\"Total failed logins: {len(failed_logins):,}\")\n",
    "    print(f\"Unique source IPs: {failed_logins['source_ip'].nunique()}\")\n",
    "    print(f\"Unique usernames targeted: {failed_logins['username'].nunique()}\")\n",
    "    \n",
    "    # Top IPs by failed attempts\n",
    "    ip_failures = failed_logins.groupby('source_ip').agg({\n",
    "        'username': ['count', 'nunique'],\n",
    "        'timestamp': ['min', 'max']\n",
    "    })\n",
    "    ip_failures.columns = ['total_failures', 'unique_users_targeted', 'first_attempt', 'last_attempt']\n",
    "    ip_failures['attack_duration_minutes'] = (\n",
    "        ip_failures['last_attempt'] - ip_failures['first_attempt']\n",
    "    ).dt.total_seconds() / 60\n",
    "    \n",
    "    ip_failures = ip_failures.sort_values('total_failures', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ TOP 10 SOURCE IPs BY FAILED ATTEMPTS:\")\n",
    "    display(ip_failures.head(10))\n",
    "    \n",
    "    # Simple brute force detection (threshold-based)\n",
    "    brute_force_threshold = 20\n",
    "    potential_attackers = ip_failures[ip_failures['total_failures'] >= brute_force_threshold]\n",
    "    \n",
    "    print(f\"\\nüö® POTENTIAL BRUTE FORCE ATTACKERS (‚â•{brute_force_threshold} failures):\")\n",
    "    if len(potential_attackers) > 0:\n",
    "        for ip, row in potential_attackers.iterrows():\n",
    "            print(f\"\\nüìç {ip}:\")\n",
    "            print(f\"   üí• Total failures: {row['total_failures']}\")\n",
    "            print(f\"   üë§ Users targeted: {row['unique_users_targeted']}\")\n",
    "            print(f\"   ‚è±Ô∏è  Attack duration: {row['attack_duration_minutes']:.1f} minutes\")\n",
    "            \n",
    "            # Show most targeted usernames for this IP\n",
    "            ip_targets = failed_logins[failed_logins['source_ip'] == ip]['username'].value_counts().head(5)\n",
    "            print(f\"   üéØ Top targets: {dict(ip_targets)}\")\n",
    "    else:\n",
    "        print(\"No IPs exceed the brute force threshold\")\n",
    "    \n",
    "    # Time-based analysis\n",
    "    failed_logins['hour'] = failed_logins['timestamp'].dt.hour\n",
    "    hourly_failures = failed_logins.groupby('hour').size()\n",
    "    \n",
    "    print(f\"\\nüïê FAILED LOGINS BY HOUR:\")\n",
    "    peak_hour = hourly_failures.idxmax()\n",
    "    print(f\"Peak hour: {peak_hour}:00 with {hourly_failures[peak_hour]} failures\")\n",
    "    \n",
    "    return {\n",
    "        'ip_failures': ip_failures,\n",
    "        'potential_attackers': potential_attackers,\n",
    "        'hourly_failures': hourly_failures,\n",
    "        'failed_logins': failed_logins\n",
    "    }\n",
    "\n",
    "# Time the basic analysis\n",
    "start_time = time.time()\n",
    "basic_auth_results = basic_auth_analysis(auth_df)\n",
    "basic_auth_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Basic analysis completed in {basic_auth_time:.2f} seconds\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.3 Machine Learning Analysis\n",
    "\n",
    "# %%\n",
    "def ml_auth_analysis(df):\n",
    "    \"\"\"ML-based authentication analysis using behavioral modeling\"\"\"\n",
    "    \n",
    "    print(\"ü§ñ ML AUTHENTICATION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create time windows for behavioral analysis\n",
    "    print(\"\\nüîß Creating behavioral features with time windows...\")\n",
    "    \n",
    "    # Use 10-minute time windows\n",
    "    df['time_window'] = df['timestamp'].dt.floor('10min')\n",
    "    \n",
    "    # Create features per IP per time window\n",
    "    window_features = df.groupby(['source_ip', 'time_window']).agg({\n",
    "        'username': ['nunique', 'count'],\n",
    "        'event_type': [lambda x: (x == 'login_failure').sum(), \n",
    "                      lambda x: (x == 'login_success').sum()],\n",
    "        'service': 'nunique'\n",
    "    })\n",
    "    \n",
    "    window_features.columns = ['unique_users', 'total_attempts', 'failures', 'successes', 'unique_services']\n",
    "    \n",
    "    # Calculate rates and ratios\n",
    "    window_features['failure_rate'] = window_features['failures'] / window_features['total_attempts']\n",
    "    window_features['attempts_per_minute'] = window_features['total_attempts'] / 10  # 10-minute windows\n",
    "    window_features['user_diversity'] = window_features['unique_users'] / window_features['total_attempts']\n",
    "    \n",
    "    # Fill NaN values\n",
    "    window_features = window_features.fillna(0)\n",
    "    \n",
    "    # Add IP-level behavioral features\n",
    "    ip_features = df.groupby('source_ip').agg({\n",
    "        'username': 'nunique',\n",
    "        'timestamp': ['count', lambda x: (x.max() - x.min()).total_seconds() / 3600],\n",
    "        'event_type': [lambda x: (x == 'login_failure').sum(), \n",
    "                      lambda x: (x == 'login_success').sum()]\n",
    "    })\n",
    "    \n",
    "    ip_features.columns = ['total_unique_users', 'total_attempts', 'session_duration_hours', \n",
    "                          'total_failures', 'total_successes']\n",
    "    ip_features['overall_failure_rate'] = ip_features['total_failures'] / ip_features['total_attempts']\n",
    "    \n",
    "    # Check if IP is external (simple heuristic)\n",
    "    ip_features['is_external'] = ~ip_features.index.str.startswith('192.168.')\n",
    "    ip_features['is_external'] = ip_features['is_external'].astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Created features for {len(window_features)} time windows across {len(ip_features)} IPs\")\n",
    "    \n",
    "    # Apply clustering to find unusual patterns in time windows\n",
    "    print(\"\\nüîç Applying DBSCAN clustering on time window features...\")\n",
    "    \n",
    "    # Select features for clustering\n",
    "    cluster_features = window_features[['unique_users', 'total_attempts', 'failure_rate', \n",
    "                                      'attempts_per_minute', 'user_diversity']].copy()\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(cluster_features)\n",
    "    \n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=3)\n",
    "    clusters = dbscan.fit_predict(features_scaled)\n",
    "    \n",
    "    # Add cluster labels\n",
    "    window_features['cluster'] = clusters\n",
    "    \n",
    "    # Analyze outliers (cluster -1)\n",
    "    outliers = window_features[window_features['cluster'] == -1]\n",
    "    \n",
    "    print(f\"\\nüö® ANOMALOUS TIME WINDOWS DETECTED: {len(outliers)}\")\n",
    "    \n",
    "    # Group outliers by IP for analysis\n",
    "    outlier_ips = outliers.groupby(level='source_ip').agg({\n",
    "        'total_attempts': ['sum', 'max'],\n",
    "        'failures': ['sum', 'max'],\n",
    "        'failure_rate': 'mean',\n",
    "        'attempts_per_minute': 'max',\n",
    "        'unique_users': 'max'\n",
    "    })\n",
    "    \n",
    "    outlier_ips.columns = ['total_attempts', 'max_attempts_per_window', 'total_failures', \n",
    "                          'max_failures_per_window', 'avg_failure_rate', \n",
    "                          'max_attempts_per_minute', 'max_users_per_window']\n",
    "    \n",
    "    # Sort by severity\n",
    "    outlier_ips['severity_score'] = (\n",
    "        outlier_ips['max_attempts_per_minute'] * 0.4 +\n",
    "        outlier_ips['avg_failure_rate'] * 0.3 +\n",
    "        outlier_ips['max_users_per_window'] * 0.3\n",
    "    )\n",
    "    \n",
    "    outlier_ips = outlier_ips.sort_values('severity_score', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ TOP SUSPICIOUS IPs BY ML ANALYSIS:\")\n",
    "    \n",
    "    for i, (ip, row) in enumerate(outlier_ips.head().iterrows()):\n",
    "        print(f\"\\n{i+1}. {ip} (severity score: {row['severity_score']:.2f})\")\n",
    "        print(f\"   üí• Total attempts: {row['total_attempts']}\")\n",
    "        print(f\"   üìà Max attempts/minute: {row['max_attempts_per_minute']:.1f}\")\n",
    "        print(f\"   ‚ùå Average failure rate: {row['avg_failure_rate']:.2%}\")\n",
    "        print(f\"   üë• Max users targeted in one window: {row['max_users_per_window']}\")\n",
    "        \n",
    "        # Show timeline for this IP\n",
    "        ip_data = df[df['source_ip'] == ip]\n",
    "        print(f\"   üìÖ Active period: {ip_data['timestamp'].min()} to {ip_data['timestamp'].max()}\")\n",
    "        \n",
    "        # Show most common usernames\n",
    "        top_users = ip_data['username'].value_counts().head(3)\n",
    "        print(f\"   üéØ Top targets: {dict(top_users)}\")\n",
    "    \n",
    "    return {\n",
    "        'window_features': window_features,\n",
    "        'ip_features': ip_features,\n",
    "        'outliers': outliers,\n",
    "        'outlier_ips': outlier_ips,\n",
    "        'clusters': clusters\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the ML analysis\n",
    "start_time = time.time()\n",
    "ml_auth_results = ml_auth_analysis(auth_df)\n",
    "ml_auth_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è ML analysis completed in {ml_auth_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
